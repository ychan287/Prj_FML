{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: FML\n",
    "#### Get Canadian Members of Parliament by Province, Electoral district and Political Party from 1972-2019 (29th-43th Parliament)\n",
    "MP's name and birthday are web scraped from their Wikipedia pages\n",
    "\n",
    "NOTES:\n",
    " - From 29th to 43rd Parliament, there are total of 4882 MP elected (combined total)\n",
    " - <b>1950 unique MP names</b>\n",
    " - <b>1795 unique Wiki profiles</b>\n",
    " - Missing Wiki profiles in most cases are for MP's that switched parties, someone replaced them etc.\n",
    " - From 1795 wiki profiles, this script 1744 birthdays - and only 51 aren't showing an actual birthday (because of the redirections, and/or additional obsticles)\n",
    " \n",
    "\n",
    "Date: March 29, 2021<br/>\n",
    "Python script: Kole Krstev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "\n",
    "# Parliaments WIKI pages url:\n",
    "#######################################################################\n",
    "# 29-35 parliament: url = 'https://en.wikipedia.org/wiki/34th_Canadian_Parliament'\n",
    "# 36-43 parliament: url = 'https://en.wikipedia.org/wiki/List_of_House_members_of_the_41st_Parliament_of_Canada'\n",
    "#######################################################################\n",
    "\n",
    "# On their Wiki pages, Canadian parliament lists has different Province table layout for different elections\n",
    "# 33,37-43rd parliaments have (\"Name\", \"Party\", \"Electoral district\") table layout\n",
    "# 29,30,31,32,34,35,36 parliament have (\"Riding\", \"Member\", \"Political Party\") table layout \n",
    "\n",
    "\n",
    "parliaments = [\"29th\",\"30th\",\"31st\",\"32nd\",\"33rd\",\"34th\",\"35th\",\"36th\",\"37th\",\"38th\",\"39th\",\"40th\",\"41st\",\"42nd\",\"43rd\"]\n",
    "\n",
    "wiki = \"https://en.wikipedia.org\"\n",
    "\n",
    "all_mps_29_43=[]\n",
    "\n",
    "\n",
    "for par in tqdm(parliaments):\n",
    "    \n",
    "    # we need to change the wiki URL based on the parliament\n",
    "    if par in [\"29th\",\"30th\",\"31st\",\"32nd\",\"33rd\",\"34th\",\"35th\"]:\n",
    "        url = \"https://en.wikipedia.org/wiki/\"+par+\"_Canadian_Parliament\"\n",
    "    else:\n",
    "        url = \"https://en.wikipedia.org/wiki/List_of_House_members_of_the_\"+par+\"_Parliament_of_Canada\"\n",
    "            \n",
    "    r = requests.get(url)\n",
    "    \n",
    "    #--------------------------------------------------------------------------------------------  \n",
    "    \n",
    "    # Use Pandas read_html function to read the tables right away from the scraped web page by the match \n",
    "    if par in [\"33rd\",\"37th\",\"38th\",\"39th\",\"40th\",\"41st\",\"42nd\",\"43rd\"]:\n",
    "        tables = pd.read_html(r.text, match=\"Electoral district\", header=0)\n",
    "    else:\n",
    "        if par==\"34th\" or par==\"35th\":\n",
    "            tables = pd.read_html(r.text, match=\"Political party\", header=0)\n",
    "        else:\n",
    "            tables = pd.read_html(r.text, match=\"Political Party\", header=0)\n",
    "\n",
    "    # Remove last element from list\n",
    "    # because on 38th page there's additional table that matches \"Electoral district\"\n",
    "    # at the very end of the page\n",
    "    if par == \"38th\":\n",
    "        tables.pop()\n",
    "    \n",
    "    for table in tables:\n",
    "        # we used pandas read_html to get the tables, but we need to get the links of the MP's wiki pages\n",
    "        # from their name by using Beautiful soup and\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        \n",
    "        if par in [\"33rd\",\"37th\",\"38th\",\"39th\",\"40th\",\"41st\",\"42nd\",\"43rd\"]:\n",
    "            for i,k in enumerate(table[\"Name\"]):\n",
    "                \n",
    "                # find the al the links that have the name as anchor text and get the href value\n",
    "                # but we'll use only the first one we find. We use find_all() vs find() because \n",
    "                # find_all doesn't give Nontype if empty, like find() (this might interfere with the value assigning)\n",
    "                link = soup.find_all('a', href=True, string=k, limit=1)\n",
    "                if len(link)>0:\n",
    "                    table.loc[i,\"Wiki_link\"] = wiki + link[0][\"href\"]\n",
    "                else:\n",
    "                    # if we don't find a link or href value (for some reason)\n",
    "                    # we'll assign this as null value\n",
    "                    table.loc[i,\"Wiki_link\"] = np.NaN\n",
    "                \n",
    "                # add the number of the Parliament as new column\n",
    "                table.loc[i, \"Parliament\"] = par[:-2]\n",
    "                \n",
    "        else:\n",
    "            for m,n in enumerate(table[\"Member\"]):\n",
    "                link = soup.find_all('a', href=True, string=n, limit=1)\n",
    "                if len(link)>0:\n",
    "                    table.loc[m,\"Wiki_link\"] = wiki + link[0][\"href\"]\n",
    "                else:\n",
    "                    table.loc[m,\"Wiki_link\"] = np.NaN\n",
    "                table.loc[m, \"Parliament\"] = par[:-2]\n",
    "        \n",
    "    # here we concatenate all provinces as a Dataframe from the N-th Parliament \n",
    "    all_province_tables = pd.concat(tables, ignore_index=True)\n",
    "       \n",
    "    # Append this Dataframe into new list\n",
    "    all_mps_29_43.append(all_province_tables)\n",
    "\n",
    "\n",
    "# Now that we have a list of all dataframes from 29-43 parliament \n",
    "# before we concatenate all of them, we need to unify them and make sure have the same columns\n",
    "#--------------------------------------------------------------------------------------------\n",
    "\n",
    "# parliaments that have table layout (Riding, Member, PoliticalParty) - that's 29,30,31,32,34,35,36 parliamants\n",
    "table_layout_1 = [\"29th\",\"30th\",\"31st\",\"32nd\",\"34th\",\"35th\",\"36th\"]\n",
    "indeces_29_30_31_32_34_35_36 = [parliaments.index(x) for x in table_layout_1]\n",
    "\n",
    "# parliaments that have table layout (Name, Party, Electoral district) - that's 33,37-43 parliamants\n",
    "table_layout_2 = [\"33rd\",\"37th\",\"38th\",\"39th\",\"40th\",\"41st\",\"42nd\",\"43rd\"]\n",
    "indeces_33_37_43 = [parliaments.index(x) for x in table_layout_2]\n",
    "    \n",
    "    \n",
    "for index,election in enumerate(all_mps_29_43):\n",
    "    \n",
    "    if index in indeces_29_30_31_32_34_35_36:\n",
    "        election.drop(columns=['Riding'], inplace=True)\n",
    "        election.rename(columns={\"Riding.1\":\"Electoral district\",\"Member\":\"Name\"}, inplace = True)\n",
    "        # if 34th or 35th parliament change the \"Political party\" to \"Party\"\n",
    "        # indices should be \"5\" and \"6\"\n",
    "        if index==5 or index==6:\n",
    "            election.rename(columns={\"Political party\":\"Party\"}, inplace = True)\n",
    "        # otherwise change the \"Political Party\" to \"Party\"\n",
    "        else:\n",
    "            election.rename(columns={\"Political Party\":\"Party\"}, inplace = True)\n",
    "        election=election[['Name', 'Party', 'Electoral district', 'Wiki_link', 'Parliament']]\n",
    "\n",
    "    elif index in indeces_33_37_43:\n",
    "        election.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "        election=election[['Name', 'Party', 'Electoral district', 'Wiki_link', \"Parliament\"]]\n",
    "\n",
    "#--------------------------------------------------------------------------------------------\n",
    "\n",
    "# create a final Dataframe of all Mp from 29-43 parliament\n",
    "Canadian_Mps_29_43 = pd.concat(all_mps_29_43, ignore_index=True)\n",
    "\n",
    "# save a CSV file from this dataframe\n",
    "Canadian_Mps_29_43.to_csv('FINAL_FINAL_MPs_from_29_43_parliament.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Canadian_Mps_29_43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Canadian_Mps_29_43.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA of the Dataframe with MP's from 31-43 Parliament\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Canadian_Mps_29_43 = pd.read_csv('FINAL_FINAL_MPs_from_29_43_parliament.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Canadian_Mps_29_43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Canadian_Mps_29_43[\"Name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we drop the duplicates if there're any\n",
    "Canadian_Mps_29_43.drop_duplicates(keep=\"first\", inplace=True)\n",
    "\n",
    "# replace all the \"*\" in the name of the Mp's\n",
    "Canadian_Mps_29_43[\"Name\"] = Canadian_Mps_29_43[\"Name\"].str.replace(\"*\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Canadian_Mps_29_43.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of Unique Wiki profiles -> total of 1794\n",
    "Canadian_Mps_29_43[\"Wiki_link\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# number of missing wiki profiles - null values (total of 214)\n",
    "Canadian_Mps_29_43[\"Wiki_link\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Unique MP's as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sift the MP's with unique wiki profile\n",
    "Mps_29_43_unique = Canadian_Mps_29_43.drop_duplicates(subset=['Wiki_link'], keep='first')\n",
    "Mps_29_43_unique.dropna(inplace=True)\n",
    "Mps_29_43_unique = Mps_29_43_unique.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mps_29_43_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mps_29_43_unique.to_csv('MP_from_29_43_parliament_UNIQUE_WIKI_link.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Missing Wiki profile MP's as CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all null wiki_link rows are exported as dataframe so we can find different option to get the birthdays\n",
    "Mps_29_43_no_wiki_profile = Canadian_Mps_29_43[Canadian_Mps_29_43[\"Wiki_link\"].isnull()]\n",
    "\n",
    "# reset index\n",
    "Mps_29_43_no_wiki_profile = Mps_29_43_no_wiki_profile.reset_index(drop=True)\n",
    "\n",
    "#save to csv\n",
    "Mps_29_43_no_wiki_profile.to_csv('MP_from_29_43_parliament_WITHOUT_WIKI_link.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mps_29_43_no_wiki_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final script to get MP's images and birthdates from their WIki page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_29_43 = pd.read_csv(\"MP_from_29_43_parliament_UNIQUE_WIKI_link.csv\", index_col=0)\n",
    "mp_29_43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################\n",
    "######## FINAL SCRIPT TO GET ALL MLP (29-43 parliamanet) images and birthdate from THEIR WIKI PAGE  ##################\n",
    "##############################################################################################################\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "for i,k in tqdm(enumerate(mp_29_43[\"Wiki_link\"])):\n",
    "    r=requests.get(k)\n",
    "    data = r.text\n",
    "    soup = BeautifulSoup(data, \"html.parser\")\n",
    "\n",
    "    #Get all the infobox sections (main top right corner info container of the wiki page)\n",
    "    #infobox = soup.select('table[class=\"infobox vcard\"]')\n",
    "    infobox = soup.find(\"table\", {\"class\":\"infobox\"})\n",
    "    # we'll use this tag to get the birthday date in case there's no infobox\n",
    "    #bdate_text = soup.select('div[id=\"bodyContent\"]')\n",
    "    bdate_text = soup.find(\"div\", {\"id\":\"bodyContent\"})\n",
    "    \n",
    "    if infobox:\n",
    "        #Wiki page can have more than one infobox section\n",
    "        #but will use only the first one to get the wiki image and birthday\n",
    "        #NOTE: We got better images for MP's from 36-43 parliament from House of Commons website\n",
    "        #If we need to use photos, we have the dataframe as csv file already\n",
    "        if infobox.find(\"img\"):\n",
    "            mp_29_43.at[i,\"Wiki_image\"]=infobox.find(\"img\").get(\"src\")\n",
    "\n",
    "        #find the table header of the Personal details section \n",
    "        #that contains the text \"Born\" or \"Born:\"\n",
    "        bd1 = soup.find(\"th\", text=\"Born\")\n",
    "        bd2 = soup.find(\"th\", text=\"Born:\")\n",
    "        \n",
    "        #if that table header exists and it has next sibling\n",
    "        #we get the birthday text\n",
    "        if bd1 or bd2:\n",
    "            if bd1:\n",
    "                mp_29_43.at[i,\"Birthday\"]=bd1.next_sibling.get_text()\n",
    "            else:\n",
    "                mp_29_43.at[i,\"Birthday\"]=bd2.next_sibling.get_text()\n",
    "        \n",
    "        else:\n",
    "            # If infobox section doesn't contain \"Born\" section we can search for the FIRST paragraph that contains\n",
    "            # the words \"born\" or \"Born\" and get the text of that paragraph\n",
    "            p = soup.find_all(\"p\", limit=1)\n",
    "            if len(p)>0:\n",
    "                if (\"born\" in p[0].text) or (\"Born\" in p[0].text):\n",
    "                    mp_29_43.at[i,\"Birthday\"]=p[0].text\n",
    "                # else get the content and use regex to match any text in \"( )\"\n",
    "                else:\n",
    "                    if bdate_text:\n",
    "                        brackets_text = re.search(r'\\((.*?)\\)', str(bdate_text))\n",
    "                        if brackets_text:\n",
    "                            mp_29_43.at[i,\"Birthday\"]=brackets_text.group(1)\n",
    "                        else:\n",
    "                            mp_29_43.at[i,\"Birthday\"]=np.NaN\n",
    "        \n",
    "    else:\n",
    "        # If there's No infobox section on this wiki page, we get the FIRST paragraph that contains the word \"born\"\n",
    "        # This might not always work but at least we get some birthdays\n",
    "        p = soup.find_all(\"p\", limit=1)\n",
    "        \n",
    "        if (\"born\" in p[0].text) or (\"Born\" in p[0].text):\n",
    "            mp_29_43.at[i,\"Birthday\"]=p[0].text\n",
    "        else:\n",
    "            # else get the content and use regex to match any text in \"( )\"\n",
    "            # check first if there's \"Citation\" at the very top of the page\n",
    "            # this box (table) might be mistakenly selected as the first paragraph of the content\n",
    "            ftable = soup.find(\"table\", {\"class\":\"box-More_citations_needed\"})\n",
    "            \n",
    "            if ftable:\n",
    "                # first paragraph is the next sibling of this table\n",
    "                nextp = ftable.find_next_siblings()\n",
    "                if nextp[0].text:\n",
    "                    brackets_text = re.search(r'\\((.*?)\\)', str(nextp[0].text))\n",
    "                    if brackets_text:\n",
    "                        mp_29_43.at[i,\"Birthday\"]=brackets_text.group(1)\n",
    "            else:\n",
    "                # if there's no Citation box\n",
    "                if bdate_text:\n",
    "                    brackets_text = re.search(r'\\((.*?)\\)', str(bdate_text))\n",
    "                    if brackets_text:\n",
    "                        mp_29_43.at[i,\"Birthday\"]=brackets_text.group(1)\n",
    "                    else:\n",
    "                        mp_29_43.at[i,\"Birthday\"]=np.NaN\n",
    "\n",
    "\n",
    "# remove all new lines in the Birthday columns\n",
    "mp_29_43[\"Birthday\"] = mp_29_43[\"Birthday\"].str.replace('\\n','', regex=True)\n",
    "\n",
    "#export to csv\n",
    "mp_29_43.to_csv(\"VERY_FINAL_FINAL_MP_from_29_43_parliament_IMAGES_and_BRITHDATES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_29_4 = pd.read_csv(\"VERY_FINAL_FINAL_MP_from_29_43_parliament_IMAGES_and_BRITHDATES.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_29_43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing Birthday fields\n",
    "mp_29_43[\"Birthday\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_29_43[mp_29_43[\"Birthday\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
